---
layout: post
title: RSN-Learning Delicate Local Representations for Multi-Person Pose Estimation
category: 技术
tags: [CNN, Pose Estimation]
description: 
---

> 旷视研究院在COCO 2019最新关于人体姿态估计的冠军方案，在不使用额外训练数据和预训练模型的情况下，集成模型在COCO test-dev上刷到了79.2。[pytorch版本源码](https://github.com/caiyuanhao1998/RSN)
>
> 人体姿态估计是计算机视觉领域中的一个重要任务，目前主流的方法分为top-down和bottom-up两种，其中top-down精度更高，但速度慢；bottom-up精度不如前者，但胜在速度。在COCO比赛中主要考察的是AP，基本所有的方案都是使用top-down。我们知道2017到2019年在该领域的的有影响力的文章都集中在模型和多尺度上，如CPN，simple baselines，MSPN，HRNet等，本文主要介绍一种新的人体姿态估计方法[Learning Delicate Local Representations for Multi-Person Pose Estimation](https://arxiv.org/abs/2003.04030)。该论文的基本框架与旷世2018年的MSPN类似，但更加关注相同level之间的特征聚合（intra-level）。

# 论文介绍

什么是层内特征融合（intra-level）？什么是层间特征融合（inter-level）？作者给出了以下解释：

<p align="center">
    <img src="/assets/img/RSN/Comparison.png">
</p>

<p align="center">
    图1.层内特征融合和层间特征融合的比较
</p>

如上图所示，图1（a）是一个传统的提取特征的backbone实例。（b）就是论文关注的重点，相同level之间的特征融合，即intra-level feature fusion，往常的SOTA方法很少关注到这一步。（c）是层间的特征融合，一些经典论文如Hourglass，CPN，MSPN[1]等都有类似的模块。从中间的融合效果以及（d）和（e）的对比来看，low-level的特征local representations能更有效的帮助网络定位出更精确的人体关键点，而global representations则是一个全局特征的考量。这就是intra-level feature fusion与inter-level feature fusion的不同之处。

作者的目的就是让local representations拥有更加强大的表达能力。因此文章提出了新的网络结构**Residual Steps Network(RSN)**。

# 网络结构

**Residual Steps Network(RSN)**网络结构具体模型如下图所示：

<p align="center">
    <img src="/assets/img/RSN/pipeline_v2.png">
</p>
<p align="center">
    图2.MS-RSN Pipeline
</p>

如上图所示，作者给出了多阶段的RSN示意图，多阶段的方式与MSPN类似。每个RSN由若干个基本单元**Residual Steps Block(RSB)**组成。据论文描述，内部结构RSB的连接方式受DenseNet启发，以此获得更好的local representations。但如果全部使用DenseNet的连接方式，在模型规模较大时，整体模型回越来越冗余。因此RSB使用element-wise sum的方式连接。同时在网络额度最后附加一个模块--Pose Refine Machine (PRM)进一步提升模型性能。

RSN有着与ResNet不同的组成单元，RSN由RSB组成，而ResNet由bottleneck组成。



# 论文方法

## Residual Steps Block

以下是RSB感受野实验结果：

<p align="center">
    <img src="/assets/img/RSN/ReceptiveFieldsofRSB.png">
</p>

论文提出RSN的目的就是更好的应用RSB模块学习local representations。从图2（c）中可以看出，RSB首先讲feature map分为4个部分 $f_i（i=1，2，3，4）$，然后实现一个conv1x1连接若干个conv3x3，每一部分的输出都与下一层连接。

如表2所示，RSB最高的感受野是15，而resnet最高只有3， 因此RSB能表示更多的局部细节。而RSB在多个分支上的连接方式与DenseNet类似，这种融合方式能将不同感受野之间存在的间隙融合，从而产生更加精致的local representations，保留了语义和空间信息。至于为什么是4个分支可以看之后的消融实验。

## Pose Refine Machine

下图为PRM的结构：

<p align="center">
    <img src="/assets/img/RSN/RM.png">
</p>
<p align="center">
    图3.Pose Refine Machine（PRM）结构
</p>

在多阶段模块的最后，会增加一个注意力机制Pose Refine Machine (PRM)，用来平衡输出特征。 

首先PRNM第一部分会连接一个conv3x3，然后feature maps会分为3路：

- top path：identity connection
- middle path：受SENet启发，通过global pooling，两个conv1x1，一个sigmoid得到weight vector
- bottom path：一个conv1x1，一个depth-wise separable conv9x9和一个sigmoid得到attention map

然后市容示意图连接方式，得到最后的输出。

# 论文实验

RSN在COCO val上的结果如下表所示：

<p align="center">
    <img src="/assets/img/RSN/results_cocoval.png">
</p>

与ResNet和Res2Net相比，RSN确实有很大的性能上的提升

# 效果展示



<p align="center">
    <img src="/assets/img/RSN/results.png">
</p>
<p align="center">
    图4.在COCO和MPII验证集上的预测结果
</p>

# 参考文献

[1] Li, W., Wang, Z., Yin, B., Peng, Q., Du, Y., Xiao, T., Yu, G., Lu, H., Wei, Y., Sun, J.: Rethinking on multi-stage networks for human pose estimation. arXiv preprint arXiv:1901.00148 (2019)

